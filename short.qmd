---
title: "Quantitative Reasoning Indirect Assessment Report"
format: 
  html:
    theme: cosmo
    toc: true
    toc-depth: 3
    toc-location: right
    number-sections: true
    self-contained: true
    anchor-sections: true
    warning: false
    message: false
  docx: 
    reference-doc: "QR_Report_Template.docx"
    toc: true
    number-sections: true
editor: source
editor_options: 
  chunk_output_type: console
echo: false
warning: false
message: false
---

```{r setup}
#| include: false
#| warning: false
#| message: false
#| echo: false

knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)

# Install and load packages
while (dev.cur() > 1) dev.off()
packages <- c("dplyr", "gtsummary", "officer", "flextable", "labelled", 
              "sjPlot", "ggplot2", "corrplot", "Hmisc", "GGally", "psych", "quarto", "readr")
invisible(lapply(setdiff(packages, rownames(installed.packages())), install.packages))
invisible(
  lapply(packages, function(pkg) {
    suppressWarnings(suppressMessages(library(pkg, character.only = TRUE)))}))

# Read data
df <- read.csv("df.csv", check.names = FALSE, stringsAsFactors = FALSE)

# Setup
var_names <- c("q1_methodology", "q2_calculation", "q3_visual_representation", "q4_interpretation",
               "q5_evaluation", "q6_coherence_purpose", "q7_reasonableness")
names(df)[2:min(8, ncol(df))] <- var_names[1:min(7, ncol(df)-1)]


# Variable groups
vars <- list(
  likert = intersect(c("q1_methodology", "q2_calculation", "q3_visual_representation", "q4_interpretation", "q5_evaluation", "q6_coherence_purpose", "q7_reasonableness"), names(df)))

# Core QR Skills
qr_core_likert <- intersect(c("q1_methodology", "q2_calculation", "q3_visual_representation", 
"q4_interpretation", "q5_evaluation", "q6_coherence_purpose", "q7_reasonableness"), names(df))


# Value maps and labels
maps <- list(
  values = list(
    likert = c("Never" = 1, "Infrequently" = 2, "Sometimes" = 3, "Frequently" = 4)),
  labels = list(
    likert = c("Never", "Infrequently", "Sometimes", "Frequently"))
)

# Variable labels
var_labels <- c(
  q1_methodology = "[Methodology] Described the methods used to solve a quantitative problem and why they were appropriate",
  q2_calculation = "[Calculation] Carried out calculations, either by hand or using software",
  q3_visual_representation = "[Visual Representation] Created a visual representation of numerical information (graph, table, chart, etc.)",
  q4_interpretation = "[Interpretation] Described numerical information (numbers, graphs, statistics, etc.) by writing in words",
  q5_evaluation = "[Evaluation] Reached conclusions based on your own analysis of numerical information (numbers, graphs, statistics, etc.)",
  q6_coherence_purpose = "[Coherence/Purpose] Constructed a single, coherent argument using several conclusions that were each based on quantitative evidence",
  q7_reasonableness = "[Reasonableness] Decided when a solution or inference was reasonable or not reasonable in the context of a problem"
)
var_labels <- var_labels[names(var_labels) %in% names(df)]

# Short labels
shortlabels <- list(
  q1_methodology = "Methodology",
  q2_calculation = "Calculation",
  q3_visual_representation = "Visual Representation",
  q4_interpretation = "Interpretation",
  q5_evaluation = "Evaluation",
  q6_coherence_purpose = "Coherence/Purpose",
  q7_reasonableness = "Reasonableness"
  )

# Create numeric and factor datasets
df_numeric <- df
df_factor <- df

# Numeric values
if(length(vars$likert) > 0) 
  df_numeric[vars$likert] <- lapply(df[vars$likert], function(x) as.numeric(maps$values$likert[x]))

# Factor dataset
df_factor[c(vars$likert)] <- df_numeric[c(vars$likert)]

if(length(vars$likert) > 0) 
  df_factor[vars$likert] <- lapply(df_factor[vars$likert], function(x) factor(x, 1:4, maps$labels$likert))


for(var in names(var_labels)) {
  if(var %in% names(df)) {
    attr(df_factor[[var]], "label") <- var_labels[var]
    attr(df_numeric[[var]], "label") <- var_labels[var]}}


#  Mean centering for multicollinearity
df_numeric$q1_methodology_cent <-scale(df_numeric$q1_methodology, center = TRUE, scale = FALSE)
df_numeric$q2_calculation_cent <-scale(df_numeric$q2_calculation, center = TRUE, scale = FALSE)
df_numeric$q3_visual_representation_cent <-scale(df_numeric$q3_visual_representation, center = TRUE, scale = FALSE)
df_numeric$q4_interpretation_cent <-scale(df_numeric$q4_interpretation, center = TRUE, scale = FALSE)
df_numeric$q5_evaluation_cent <-scale(df_numeric$q5_evaluation, center = TRUE, scale = FALSE)
df_numeric$q6_coherence_purpose_cent <-scale(df_numeric$q6_coherence_purpose, center = TRUE, scale = FALSE)
df_numeric$q7_reasonableness_cent <-scale(df_numeric$q7_reasonableness, center = TRUE, scale = FALSE)
```

# Study

## Background

A survey, Indirect Assessment in Quantitative Reasoning, was used to complement the [Quantitative Reasoning Rubric](https://drive.google.com/file/d/1eij-N3jRgmW2dth-U7Mz3qb-zrdcTRJk/view) for direct assessment.

## Method and Sample

The survey was distributed through Google Forms to assess quantitative reasoning skills and engagement using the "Short Form."

The data was collected during the last two weeks of the Spring 2024 semester, resulting in 469 complete student responses.

## Variables

Variable names, full wording of the questions, short labels used in analyses, and the response sets are as follows.

```{r variables}

codebook <- data.frame(
  variable_name = c(
    "q1_methodology", "q2_calculation", "q3_visual_representation", 
    "q4_interpretation", "q5_evaluation", "q6_coherence_purpose", 
    "q7_reasonableness"
  ),
  
  full_question = c(
    "[Methodology] Throughout this course, how often have you done each of the following?... Describe the methods that you chose to solve a quantitative problem and why they were appropriate.
    
Never (1) / Infrequently (2) / Sometimes (3) / Frequently (4)",
    "[Calculation]... Carried out calculations, either by hand or using software.
    
Never (1) / Infrequently (2) / Sometimes (3) / Frequently (4)",
    "[Visual Representation]... Created a visual representation of numerical information, such as a graph, table, chart, or diagram.
    
Never (1) / Infrequently (2) / Sometimes (3) / Frequently (4)",
    "[Interpretation]... Described numerical information (numbers, graphs, statistics, etc.) by writing in words.
    
Never (1) / Infrequently (2) / Sometimes (3) / Frequently (4)",
    "[Evaluation]... Reached conclusions based on your own analysis of numerical information (numbers, graphs, statistics, etc.)
    
Never (1) / Infrequently (2) / Sometimes (3) / Frequently (4)",
    "[Coherence/Purpose]... Constructed a single, coherent argument using several conclusions that were each based on quantitative evidence.
    
Never (1) / Infrequently (2) / Sometimes (3) / Frequently (4)",
    "[Reasonableness]... Decided when a solution or inference was reasonable or not reasonable in the context of a problem."  
), stringsAsFactors = FALSE)

ft <- flextable(codebook) %>%
  flextable::width(j = 1, width = 1.7) %>%  
  flextable::width(j = 2, width = 4.7) %>% 

  flextable::font(fontname = "Arial", part = "all") %>%
  flextable::fontsize(size = 9, part = "all") %>%
  flextable::padding(padding = 4, part = "all") %>%
  flextable::bold(part = "header") %>%
  flextable::set_header_labels(
    variable_name = "Variable Name",
    full_question = "[Short label] Full Wording of the Question and the Response Set"
  ) %>%
  flextable::border_outer() %>%
  flextable::border_inner_h()
ft
```

# Results

## Quantitative Reasoning Skills: Summary

### Table 1. Frequencies of Core Quantitative Reasoning Skills

```{r frequency-table-core}
if (length(qr_core_likert) > 0) {
  tbl <- df_factor %>% 
    select(all_of(qr_core_likert)) %>%
    tbl_summary(
      statistic = everything() ~ "{n} ({p}%)",
      missing = "no"
    ) %>%
    modify_header(label = "Core QR Skills - Items") %>%
    italicize_levels() %>%
    modify_table_body(
      ~ .x %>%
        dplyr::mutate(
          label = dplyr::if_else(variable != lag(variable) | is.na(lag(variable)), label, paste0("    ", label))
        )
    )
  tbl_flex <- as_flex_table(tbl) %>%
    flextable::width(j = 1, width = 5) %>%
    flextable::width(j = 2, width = 2) %>%
    flextable::font(fontname = "Arial", part = "all") %>%
    flextable::fontsize(size = 10, part = "all") %>%
    flextable::padding(padding = 1, part = "all")

  tbl_flex
}
```

**Table 1** presents the frequencies of student engagement in various quantitative activities within the class, measured through seven different questions.

"Carried out calculations, either by hand or using software," shows that a significant majority of students, 65%, frequently engage in calculations. "Created a visual representation, like a graph, chart, or diagram," indicates that 56.5% of students frequently create visual representations. "Interpreted numerical information by writing in words," shows 54.1% of students frequently interpret numerical data in written form.

The last three items received the least “frequently” responses display more advanced quantitative reasoning and analysis."Described the methods used to solve a quantitative problem and why they were appropriate" shows 40.3% of students frequently describe methodology. "Decided when a solution or inference was reasonable or not reasonable in the context of a problem" indicates that 38.2% of students frequently assess reasonableness. Finally, the item "Constructed a single, coherent argument using several conclusions that were each based on quantitative evidence" has the lowest "frequently" response at 34.2%, which is less common among students.

### Figure 1. Frequencies of Core Quantitative Reasoning Skills

```{r frequency-graph-core, fig.width=11, fig.height=7}
#| fig-cap: "Note 1: Alternative of the above table.<br>Note 2: The items are sorted by the responses that received the most 'frequently' responses."

value_labels <- c("1" = "Never", "2" = "Infrequently", "3" = "Sometimes", "4" = "Frequently")
graph <- df_numeric %>%  
  select(all_of(qr_core_likert)) %>%  
  plot_stackfrq(
    sort.frq = "last.desc", 
    coord.flip = TRUE, 
    geom.colors = "Blues", 
    show.total = FALSE,
    legend.labels = value_labels,
    axis.labels = shortlabels[qr_core_likert])
graph + theme(
  axis.text.x = element_text(size=14),  
  axis.text.y = element_text(size=14),  
  plot.title = element_text(size=14),  
  legend.text = element_text(size=14),
  legend.position = "bottom")
```

### Table 2. Descriptive Statistics of Core Quantitative Reasoning Skills

```{r descriptive-table-core}

if (length(qr_core_likert) > 0) {
  means <- sapply(df_numeric[qr_core_likert], mean, na.rm = TRUE)
  sorted_vars <- names(sort(means, decreasing = TRUE))

  tbl <- df_numeric %>%
    select(all_of(sorted_vars)) %>%
    tbl_summary(
      type = everything() ~ "continuous",
      statistic = everything() ~ "{mean} ({sd})",
      digits = everything() ~ 2,
      missing = "no"
    ) %>%
    modify_header(label = "Core QR Skills - Items")

  tbl_flex <- as_flex_table(tbl) %>%
    flextable::width(j = 1, width = 5) %>%
    flextable::width(j = 2, width = 2) %>%
    flextable::font(fontname = "Arial", part = "all") %>%
    flextable::fontsize(size = 10, part = "all") %>%
    flextable::padding(padding = 4, part = "all")

  tbl_flex
}
```

**Table 2** presents the descriptive statistics of core quantitative reasoning skills. The highest mean score is for "Calculation" at 3.55 out of four. "Visual representation" has a mean score of 3.43. "Interpretation" and "Evaluation" both have a mean score of 3.38. Students describe numerical information in written form and reach conclusions based on analysis at similar frequencies.

"Reasonableness" and "Methodology" both score 3.20. Students decide when solutions are reasonable in context and describe methods used to solve quantitative problems at moderate frequencies. "Coherence/Purpose," which involves constructing coherent arguments using multiple quantitative conclusions, has a mean score of 3.03. Students construct coherent arguments using several conclusions based on quantitative evidence less frequently than other skills.

The standard deviations range from 0.70 to 0.88, with "Coherence/Purpose" showing the highest variability among students (SD = 0.88). In contrast, "Calculation" (SD = 0.70) and "Visual Representation" (SD = 0.75) show more consistent performance across students.

### Figure 2. Descriptive Statistics of Quantitative Reasoning Skills

```{r descriptive-figure-core, fig.width=11, fig.height=7}
#| fig-cap: "Note: Alternative of the above table."
stats_df <- data.frame(
  variable = qr_core_likert,
  stringsAsFactors = FALSE)

for(var in qr_core_likert) {
  stats_df$mean[stats_df$variable == var] <- mean(df_numeric[[var]], na.rm = TRUE)
  stats_df$sd[stats_df$variable == var] <- sd(df_numeric[[var]], na.rm = TRUE)}

stats_df$label <- unlist(shortlabels[stats_df$variable])
stats_df$stat_label <- sprintf("%.2f (%.2f)", stats_df$mean, stats_df$sd)

ggplot(stats_df, aes(x = reorder(label, mean), y = mean)) +
  geom_col(fill = "#4682B4", width = 0.7) +
  geom_text(aes(label = stat_label), 
            hjust = -0.1,
            size = 4,
            color = "black") +
  scale_y_continuous(
    limits = c(0, 4.0),
    breaks = 1:4,
    labels = c("1\nNever", "2\nInfrequently", "3\nSometimes", "4\nFrequently"),
    expand = expansion(mult = c(0, 0.1))
  ) +
  labs(
    x = "",
    y = "Mean (SD) (1-4 scale)"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(size = 13),
    axis.text.y = element_text(size = 13),
    axis.title.x = element_text(size = 13),
    panel.grid.minor = element_blank(),
    panel.grid.major.y = element_blank(),
    panel.grid.major.x = element_line(color = "lightgray"),
    panel.background = element_rect(fill = "white", color = NA),
    plot.background = element_rect(fill = "white", color = NA),
    axis.line.x = element_line(color = "black"),
    plot.margin = margin(10, 60, 10, 10)
  ) +
  coord_flip()
```

# Correlation Analyses

## Figure 3. Correlation Matrix of All Variables

```{r correlation-matrix-core, fig.width=18, fig.height=15}
#| fig-cap: "Note: Bottom-left cells show scatterplots; diagonal cells show variable distributions. Top-right values are Pearson *r* coefficients. Correlation strength: weak (|r| < 0.3), moderate (0.3 < |r| < 0.5), strong (|r| > 0.5). * p < .05, ** p < .01, *** p < .001."

df_pairs <- df_numeric[, c("q1_methodology", "q2_calculation", "q3_visual_representation", 
                           "q4_interpretation", "q5_evaluation", "q6_coherence_purpose", 
                           "q7_reasonableness"
                           )]
names(df_pairs) <- unlist(shortlabels[names(df_pairs)])

par(mar = c(6, 5, 4, 2) + 0.1)

pairs.panels(
  df_pairs,
  ellipses       = FALSE,
  scale          = FALSE,
  show.points    = FALSE,
  stars          = TRUE,
  ci             = TRUE,  
  cex.labels     = 1.9,
  cex.cor        = 1.2,
  hist.col       = "black", 
  lm.col         = "black", 
  cor.col        = "black",
  col            = "black"
  )
```

**Figure 9** presents the correlation matrix of all variables.

The strongest correlations within the core quantitative reasoning skills are observed between:

-   Coherence/Purpose and Reasonableness (*r* = 0.68, *p*\<0.001)

-   Evaluation and Interpretation (*r* = 0.64, *p*\<0.001)

-   Interpretation and Visual Representation (*r* = 0.61, *p*\<0.001)

These strong correlations may suggest that students who build coherent arguments backed by quantitative evidence also tend to judge the reasonableness of solutions. Students with strong evaluation skills typically have strong interpretation abilities, and those who interpret numerical information also create visual representations of data.

## Figure 4. Correlogram of All Variables

```{r correlogram, fig.width=22, fig.height=20}
#| fig-cap: "Note 1: Alternative of the above graph.<br>Note 2: Cells represent the correlation coefficient between two variables. Blue shows positive correlations, red shows negative correlations, and circle size reflects correlation magnitude. Correlation strength: weak (|r| < 0.3), moderate (0.3 < |r| < 0.5), strong (|r| > 0.5). Insignificant correlations are invisible (p > .05)."
#| warning: false
#| message: false

selectedvariables <- c(
  "q1_methodology", "q2_calculation", "q3_visual_representation", 
  "q4_interpretation", "q5_evaluation", "q6_coherence_purpose", 
  "q7_reasonableness" 
)
testRes <- cor.mtest(df_numeric[, selectedvariables])
qrrcorr <- rcorr(as.matrix(df_numeric[, selectedvariables]))
qrcoeff <- qrrcorr$r

colnames(qrcoeff) <- unlist(shortlabels[selectedvariables])
rownames(qrcoeff) <- unlist(shortlabels[selectedvariables])
colnames(testRes$p) <- unlist(shortlabels[selectedvariables])
rownames(testRes$p) <- unlist(shortlabels[selectedvariables])

invisible(
  corrplot(
    qrcoeff,
    p.mat = testRes$p,
    method = 'pie',
    type = 'lower',
    tl.srt = 30,  
    insig = 'blank',
    addCoef.col = 'black',
    order = 'original',
    diag = FALSE,
    tl.cex = 2.1,  
    cl.cex = 1.9,
    tl.col = "black", 
    number.cex = 2.2,
    number.font = 1
  )
)
```

# Regression Analyses

## Table 3. Linear Regression Model Predicting Coherence/Purpose

```{r regression-model1}
model1 <- lm(q6_coherence_purpose_cent ~ q1_methodology_cent + q2_calculation_cent +
               q3_visual_representation_cent + q4_interpretation_cent +
               q5_evaluation_cent + q7_reasonableness_cent, data = df_numeric)
coef_table <- summary(model1)$coefficients
conf_int <- confint(model1, level = 0.95)

format_p_with_stars <- function(p) {
  stars <- ""
  if (p < 0.001) stars <- "***"
  else if (p < 0.01) stars <- "**"
  else if (p < 0.05) stars <- "*"
  else if (p < 0.1) stars <- "†"
  
  p_formatted <- ifelse(p < 0.001, "0.000", sprintf("%.3f", p))
  return(list(p_value = p_formatted, stars = stars))
}

table_data <- data.frame(
  Predictors = c("Intercept", "Methodology", "Calculation", "Visual Representation", 
                 "Interpretation", "Evaluation", "Reasonableness"),
  Estimate = sprintf("%.2f", coef_table[,1]),
  Stars = sapply(coef_table[,4], function(p) format_p_with_stars(p)$stars),
  SE = sprintf("%.2f", coef_table[,2]),
  CI = sprintf("[%.2f, %.2f]", conf_int[,1], conf_int[,2]),
  p = sapply(coef_table[,4], function(p) format_p_with_stars(p)$p_value)
)

table_data$Estimate <- paste0(table_data$Estimate, table_data$Stars)
table_data$Stars <- NULL
table_data$SE <- paste0("(", table_data$SE, ")")

tbl_flex <- flextable(table_data) %>%
  set_header_labels(
    Predictors = "Predictor",
    Estimate = "Estimate",
    SE = "SE",
    CI = "95% CI",
    p = "p-value"
  ) %>%
  add_header_row(
    values = "Linear Regression Model Predicting Coherence/Purpose",
    colwidths = 5
  ) %>%
  fontsize(size = 10, part = "all") %>%
  font(fontname = "Arial", part = "all") %>%
  width(j = 1, width = 3) %>%
  width(j = 2:5, width = 1.3) %>%
  align(align = "left", j = 1, part = "all") %>%
  align(align = "center", j = 2:5, part = "all") %>%
  padding(padding = 4, part = "all") %>%
  set_table_properties(layout = "autofit")

footer_text <- c(
  "SE = Standard Error, CI = Confidence Interval",
  "† p < .10, * p < .05, ** p < .01, *** p < .001",
  sprintf("R² = %.3f; Adjusted R² = %.3f", summary(model1)$r.squared, summary(model1)$adj.r.squared)
)

combined_footer <- paste(footer_text, collapse = "\n")

tbl_flex <- tbl_flex %>%
  add_footer_lines(values = combined_footer) %>%
  fontsize(size = 10, part = "footer") %>%
  font(fontname = "Arial", part = "footer") %>%
  padding(padding = 2, part = "footer")

tbl_flex
```
A linear regression was conducted to identify the factors that influence students’ ability to construct a single, coherent argument using several conclusions based on quantitative evidence—referred to as "Coherence/Purpose." This item received the lowest "frequently" responses at 34.2%, as noted in prior sections. Note that all variables were mean-centered prior to analyses to minimize multicollinearity.

The results reveal that four skills significantly influence the ability to construct coherent quantitative arguments. Specifically, the skill of describing the methods used to solve a quantitative problem and justifying their appropriateness increases the "Coherence/Purpose" score by 0.21 points on a 1-to-4 scale. Similarly, the ability to reach conclusions based on one’s own analysis of numerical information, such as numbers, graphs, or statistics, increases the score by 0.24 points. The most substantial impact arises from deciding when a solution or inference is reasonable within a problem’s context, which increases the Coherence/Purpose score by 0.53 points. Finally, "Carried out calculations, either by hand or using software” shows a negative effect, decreasing the Coherence/Purpose score by 0.11 points. This effect is significant at a marginal level (*p* \< 0.10), a less reliable but noteworthy influence that warrants further exploration. The model explains approximately 51.1% of the variance in "Coherence/Purpose" (R² = 0.511).

